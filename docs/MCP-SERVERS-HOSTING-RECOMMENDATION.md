# MCP Servers Hosting Recommendation

**Date**: January 17, 2026  
**Status**: âœ… **RECOMMENDED APPROACH**

---

## ğŸ¯ Recommendation: Host as HTTP Endpoints

**Yes, you should host these MCP servers on your server as HTTP endpoints**, similar to your draft pool MCP server.

---

## âœ… Benefits of HTTP-Based Hosting

### 1. **Serverless Compatibility**
- âœ… Works with Vercel/serverless environments
- âœ… No Docker container startup overhead
- âœ… Better performance (no subprocess spawning)
- âœ… Connection pooling and reuse

### 2. **Public Accessibility**
- âœ… Accessible via Cloudflare Tunnel (like draft pool MCP)
- âœ… Can be used by multiple clients simultaneously
- âœ… Better for production deployments

### 3. **Consistency**
- âœ… Same architecture as draft pool MCP
- âœ… Unified deployment and monitoring
- âœ… Easier to manage and scale

### 4. **Performance**
- âœ… No Docker command execution overhead
- âœ… Persistent connections
- âœ… Better error handling and retries

---

## ğŸ“‹ Current Setup (Draft Pool MCP)

**Server**: `moodmnky@10.3.0.119`  
**Location**: `/home/moodmnky/POKE-MNKY/tools/mcp-servers/draft-pool-server/`  
**Port**: `3001:3000` (external:internal)  
**Cloudflare Tunnel**: `https://mcp-draft-pool.moodmnky.com/mcp`  
**Transport**: Streamable HTTP  
**Docker Service**: `draft-pool-mcp-server` in `docker-compose.yml`

---

## ğŸ—ï¸ Proposed Architecture

### Option 1: Individual HTTP MCP Servers (Recommended)

Create separate HTTP MCP servers for each service:

1. **Sequential Thinking MCP** â†’ `https://mcp-sequential.moodmnky.com/mcp` (Port 3002)
2. **Brave Search MCP** â†’ `https://mcp-brave.moodmnky.com/mcp` (Port 3003)
3. **Tavily MCP** â†’ `https://mcp-tavily.moodmnky.com/mcp` (Port 3004)
4. **Firecrawl MCP** â†’ `https://mcp-firecrawl.moodmnky.com/mcp` (Port 3005)
5. **Fetch MCP** â†’ `https://mcp-fetch.moodmnky.com/mcp` (Port 3006)

**Pros**:
- âœ… Independent scaling
- âœ… Individual health checks
- âœ… Easier debugging
- âœ… Can update one without affecting others

**Cons**:
- âš ï¸ More services to manage
- âš ï¸ More Cloudflare Tunnel routes

---

### Option 2: Unified Research MCP Server (Alternative)

Create a single HTTP MCP server that combines all research tools:

**Research Tools MCP** â†’ `https://mcp-research.moodmnky.com/mcp` (Port 3002)

**Pros**:
- âœ… Single service to manage
- âœ… Unified API
- âœ… Easier deployment
- âœ… Can use existing solutions like `mcp-omnisearch`

**Cons**:
- âš ï¸ All tools tied together
- âš ï¸ Harder to scale individually

---

## ğŸš€ Implementation Plan

### Phase 1: Use Existing Solutions (Fastest)

**For Firecrawl**: Use Firecrawl's native HTTP MCP server

```bash
# Firecrawl has built-in HTTP MCP support
# Can be self-hosted or use their cloud endpoint
```

**For Search Tools**: Use `mcp-omnisearch` (combines Brave, Tavily, etc.)

```bash
# GitHub: spences10/mcp-omnisearch
# Supports HTTP transport
# Combines multiple search providers
```

**For Sequential Thinking**: Create simple HTTP wrapper

```bash
# Wrap the Docker stdio server in HTTP
# Or use existing HTTP-based reasoning server
```

---

### Phase 2: Custom HTTP MCP Servers (If Needed)

If existing solutions don't meet requirements, create custom HTTP MCP servers following the draft pool MCP pattern:

**Structure**:
```
/home/moodmnky/POKE-MNKY/tools/mcp-servers/
â”œâ”€â”€ draft-pool-server/          # âœ… Existing
â”œâ”€â”€ sequential-thinking-server/ # ğŸ†• New
â”œâ”€â”€ brave-search-server/        # ğŸ†• New
â”œâ”€â”€ tavily-server/             # ğŸ†• New
â”œâ”€â”€ firecrawl-server/          # ğŸ†• New (or use Firecrawl's native)
â””â”€â”€ fetch-server/              # ğŸ†• New
```

**Each server**:
- Express.js HTTP server
- Streamable HTTP transport
- MCP SDK integration
- Docker containerization
- Cloudflare Tunnel exposure

---

## ğŸ“ Docker Compose Configuration

### Example: Sequential Thinking MCP Server

```yaml
# docker-compose.yml
services:
  sequential-thinking-mcp-server:
    build: ./tools/mcp-servers/sequential-thinking-server
    container_name: poke-mnky-sequential-thinking-mcp-server
    ports:
      - "3002:3000"
    environment:
      - PORT=3000
    networks:
      - poke-mnky-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
```

### Cloudflare Tunnel Routes

Add to Cloudflare Tunnel configuration:

```
mcp-sequential.moodmnky.com â†’ 10.3.0.119:3002
mcp-brave.moodmnky.com â†’ 10.3.0.119:3003
mcp-tavily.moodmnky.com â†’ 10.3.0.119:3004
mcp-firecrawl.moodmnky.com â†’ 10.3.0.119:3005
mcp-fetch.moodmnky.com â†’ 10.3.0.119:3006
```

---

## ğŸ”„ Updated Agent Configuration

Once HTTP endpoints are available, update `lib/agents/mcp-servers.ts`:

```typescript
// HTTP-based MCP Servers (Streamable HTTP)
export const sequentialThinkingMCP = new MCPServerStreamableHttp({
  url: process.env.MCP_SEQUENTIAL_THINKING_URL || 'https://mcp-sequential.moodmnky.com/mcp',
  name: 'sequential-thinking',
  cacheToolsList: true,
})

export const braveSearchMCP = new MCPServerStreamableHttp({
  url: process.env.MCP_BRAVE_SEARCH_URL || 'https://mcp-brave.moodmnky.com/mcp',
  name: 'brave-search',
  cacheToolsList: true,
})

// ... etc
```

---

## ğŸ“Š Comparison: Stdio vs HTTP

| Aspect | Stdio (Current) | HTTP (Recommended) |
|--------|----------------|-------------------|
| **Serverless** | âŒ Doesn't work | âœ… Works perfectly |
| **Performance** | âš ï¸ Container startup overhead | âœ… Persistent connections |
| **Scalability** | âš ï¸ Limited | âœ… Excellent |
| **Public Access** | âŒ Local only | âœ… Cloudflare Tunnel |
| **Error Handling** | âš ï¸ Basic | âœ… Advanced retries |
| **Monitoring** | âš ï¸ Difficult | âœ… Health checks, logs |

---

## ğŸ¯ Recommended Approach

### Step 1: Use Existing Solutions (Week 1)

1. **Firecrawl**: Use their native HTTP MCP endpoint
   - Self-hosted or cloud
   - Already supports HTTP/Streamable HTTP

2. **Search Tools**: Deploy `mcp-omnisearch`
   - Combines Brave, Tavily, and more
   - HTTP transport support
   - Single service for all search tools

3. **Sequential Thinking**: Create simple HTTP wrapper
   - Wrap existing Docker stdio server
   - Or use HTTP-based reasoning service

### Step 2: Custom Servers (If Needed) (Week 2-3)

If existing solutions don't meet requirements:
- Follow draft pool MCP pattern
- Create HTTP MCP servers for each tool
- Deploy via Docker Compose
- Expose via Cloudflare Tunnel

---

## ğŸ”§ Environment Variables

Add to `.env` and `.env.local`:

```bash
# MCP Server URLs (HTTP-based)
MCP_SEQUENTIAL_THINKING_URL=https://mcp-sequential.moodmnky.com/mcp
MCP_BRAVE_SEARCH_URL=https://mcp-brave.moodmnky.com/mcp
MCP_TAVILY_URL=https://mcp-tavily.moodmnky.com/mcp
MCP_FIRECRAWL_URL=https://mcp-firecrawl.moodmnky.com/mcp
MCP_FETCH_URL=https://mcp-fetch.moodmnky.com/mcp

# Or unified research server:
MCP_RESEARCH_TOOLS_URL=https://mcp-research.moodmnky.com/mcp
```

---

## âœ… Next Steps

1. **Decide on approach**: Individual servers vs unified research server
2. **Research existing solutions**: Check `mcp-omnisearch`, Firecrawl HTTP MCP
3. **Create implementation plan**: Based on chosen approach
4. **Deploy to server**: Follow draft pool MCP pattern
5. **Update agent configuration**: Switch from stdio to HTTP
6. **Test and verify**: Ensure all tools work via HTTP

---

## ğŸ“š Resources

- **Draft Pool MCP**: `/home/moodmnky/POKE-MNKY/tools/mcp-servers/draft-pool-server/`
- **Firecrawl MCP Docs**: https://docs.firecrawl.dev/mcp-server
- **MCP Omnisearch**: https://github.com/spences10/mcp-omnisearch
- **Cloudflare Tunnel**: Already configured for draft pool MCP

---

**Recommendation**: Start with existing solutions (`mcp-omnisearch` for search, Firecrawl's native HTTP for scraping), then create custom servers only if needed. This will be faster and more maintainable.
